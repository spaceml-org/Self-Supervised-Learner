# -*- coding: utf-8 -*-
"""test TSNE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L09k6A23HIF8Ao48i6oQiS2ATGreyDiQ
"""

import numpy as np
import pandas as pd
import time
from pathlib import Path
import sys
from torchvision import transforms
from ssl_dali_distrib import SIMCLR 
from finetuner_dali_distrib import finetuner
import torch
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, f1_score, recall_score

import os
import itertools
import shutil
import PIL
import torch
from torch import nn
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import PIL.Image as Image
import time

import pickle
from tqdm import tqdm
import random
import time
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import PIL
from sklearn.neighbors import NearestNeighbors
import glob
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib.cbook import get_sample_data
from sklearn.preprocessing import LabelEncoder
from argparse import ArgumentParser


def load_checkpoint(MODEL_PATH):
    #expects a checkpoint path, not an encoder
    try:
        model = finetuner.load_from_checkpoint(MODEL_PATH)
        is_classifier = True
    except:
        model = SIMCLR.load_from_checkpoint(MODEL_PATH)
        is_classifier = False
    return model, is_classifier

def get_matrix(MODEL_PATH, DATA_PATH):
    def to_tensor(pil):
        return torch.tensor(np.array(pil)).permute(2,0,1).float()
    t = transforms.Compose([
                            transforms.Resize((48,48)),
                            transforms.Lambda(to_tensor)
                            ])
    dataset = ImageFolder(DATA_PATH, transform = t)
    model, is_classifier = load_checkpoint(MODEL_PATH)
    model.eval()
    model.cuda()
    if is_classifier:
      size = model.num_classes
    else:
      size = model.embedding_size
    with torch.no_grad():
        data_matrix = torch.empty(size = (0, size)).cuda()
        bs = 256
        if len(dataset) < bs:
          bs = 1
        loader = DataLoader(dataset, batch_size = bs, shuffle = False)
        for batch in tqdm(loader):
            x = batch[0].cuda()
            embeddings = model(x)
            data_matrix = torch.cat([data_matrix, embeddings])
    return data_matrix.cpu().detach().numpy(), dataset.imgs


class TSNE_visualiser: 
    def __init__(self, feature_list, filenames):
        # '''
        # params:
        # feature_list : Embeddings list
        # filenames: filenames for the images in the embeddings list
        # '''
        self.feature_list = feature_list
        self.filenames = filenames
        self.labels = []
        for _ in filenames:
            self.labels.append(_.split("/")[-2])

    # return train_data_reshaped, labels, feature_list

    def fit_tsne(self, perplexity= 30, n_jobs= 4):
    # '''
    # Fits TSNE for the input embeddings
    # feature_list: ssl embeddings
    # perplexity : hyperparameter that determines how many images are close to each other in a cluster
    # n_jobs : number of jobs to be run concurrently. 
    # '''
        n_components = 2
        verbose = 1
        perplexity = perplexity
        n_iter = 1000
        metric = 'euclidean'
        n_jobs= n_jobs

        time_start = time.time()
        tsne_results = TSNE(n_components=n_components,
                            verbose=verbose,
                            perplexity=perplexity,
                            n_iter=n_iter,
                            n_jobs= n_jobs,
                            metric=metric).fit_transform(self.feature_list)

        print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))
        return tsne_results
    
    def scatter_plot(self, tsne_results):
    # '''
    # Plots a scatter plot for the given TSNE fit variable
    # '''
        # le = LabelEncoder()
        # class_labels = le.fit_transform(labels)
        color_map = plt.cm.get_cmap('tab20b_r')
        scatter_plot = plt.scatter(tsne_results[:, 0],
                                tsne_results[:, 1],
                                # c=class_labels,
                                cmap=color_map)
        
        plt.colorbar(scatter_plot)
        plt.title('TSNE of Embeddings');
        fname = './TSNE_Scatter.png'
        plt.savefig(fname)

    def plot_images_in_2d(self, x, y, image_vectors, axis=None, zoom=1):
    # '''
    # Helper function, do not call. 
    # params:
    # x, y : TSNE variables
    # image_vectors: images in the dataset
    # '''
        if axis is None:
            axis = plt.gca()
        x, y = np.atleast_1d(x, y)
        for x0, y0, image_path in zip(x, y, image_vectors):
            image = Image.open(image_path)
            image.thumbnail((100, 100), Image.ANTIALIAS)
            img = OffsetImage(image, zoom=zoom)
            anno_box = AnnotationBbox(img, (x0, y0),
                                    xycoords='data',
                                    frameon=False)
            axis.add_artist(anno_box)
        axis.update_datalim(np.column_stack([x, y]))
        axis.autoscale()

    def show_tsne(self, x, y, images):
      
      fig, axis = plt.subplots()
      fig.set_size_inches(22, 22, forward=True)
      self.plot_images_in_2d(x, y, images, zoom=0.3, axis=axis)
      fname = './TSNE_regplot.png'
      plt.savefig(fname)

    def tsne_to_grid_plotter_manual(self, x, y, selected_filenames):
      # '''
      # TSNE visualiser with evenly spaced out images
      # params:
      # x, y : TSNE variables
      # selected_filenames: images in the dataset
      # '''
          S = 2000
          s = 100
          x = (x - min(x)) / (max(x) - min(x))
          y = (y - min(y)) / (max(y) - min(y))
          x_values = []
          y_values = []
          filename_plot = []
          x_y_dict = {}
          for i, image_path in enumerate(selected_filenames):
              a = np.ceil(x[i] * (S - s))
              b = np.ceil(y[i] * (S - s))
              a = int(a - np.mod(a, s))
              b = int(b - np.mod(b, s))
              if str(a) + "|" + str(b) in x_y_dict:
                  continue
              x_y_dict[str(a) + "|" + str(b)] = 1
              x_values.append(a)
              y_values.append(b)
              filename_plot.append(image_path)
          fig, axis = plt.subplots()
          fig.set_size_inches(22, 22, forward=True)
          self.plot_images_in_2d(x_values, y_values, filename_plot, zoom=.58, axis=axis)
          fname = './TSNE_GridPlot.png'
          plt.savefig(fname)

if __name__ == '__main__':
    parser = ArgumentParser()
    parser.add_argument("--DATA_PATH", type=str, help="path to folders with images")
    parser.add_argument("--MODEL_PATH", type=str, help="path to ssl model")
    parser.add_argument("--grid", type=bool, default = False, help="plot in 2d grid")
    args = parser.parse_args()
    
    DATA_PATH = args.DATA_PATH
    MODEL_PATH = args.MODEL_PATH
    grid = args.grid
    
    embeddings, ims = get_matrix(MODEL_PATH, DATA_PATH)
    tsne = TSNE_visualiser(embeddings, [f[0] for f in ims])
    result = tsne.fit_tsne()
    if grid:
        tsne.tsne_to_grid_plotter_manual(result[:, 0], result[:, 1], tsne.filenames)
    else:
        tsne.show_tsne(result[:, 0], result[:, 1], tsne.filenames)

